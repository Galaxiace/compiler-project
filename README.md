# MiniCompiler — Лексический анализатор (Спринт 1)

Учебный проект компилятора для упрощенного C-подобного языка. Реализован лексический анализатор (сканер), который преобразует исходный код в последовательность токенов.

## Структура проекта

```
compiler-project/
│
│
├── lexer/                                        # Основной пакет лексера
│   ├── init.py                                   # Делает директорию пакетом Python
│   ├── cli.py                                    # Интерфейс командной строки
│   ├── errors.py                                 # Классы ошибок лексического анализа
│   ├── scanner.py                                # Основная логика сканера
│   └── token.py                                  # Определения токенов и их типов
│
│
├── tests/                                        # Тесты
│   ├── init.py
│   ├── test_lexer.py                             # Модульные тесты
│   └── lexer/                                    # Тестовые файлы
│       ├── valid/                                # Валидные тестовые примеры
│       │   ├── test_basic.src
│       │   └── test_operators.src
│       └── invalid/                              # Невалидные тестовые примеры
│           ├── test_invalid_char.src
│           └── test_unterminated_string.src
│
│
├── docs/                                         # Документация
│   └── language_spec.md                          # Спецификация языка
│
│
├── examples/                                     # Примеры кода
│
│
├── requirements.txt                              # Зависимости проекта
├── setup.py                                      # Установочный файл
└── README.md                                     # Этот файл
```

## Тестирование 

### Запуск всех тестов
```bash

pytest tests/ -v
```

### Тестирование файла с базовыми конструкциями
```bash

python -m lexer.cli --input tests/lexer/valid/test_basic.src
```

### Тестирование файла с операторами
```bash

python -m lexer.cli --input tests/lexer/valid/test_operators.src
```

### Тестирование файла с недопустимыми символами
```bash

python -m lexer.cli --input tests/lexer/invalid/test_invalid_char.src
```

### Тестирование файла с незакрытой строкой
```bash

python -m lexer.cli --input tests/lexer/invalid/test_unterminated_string.src
```

## Детальное описание компонентов

### 1. Пакет `lexer/` — ядро лексического анализатора

#### `token.py` — определение токенов
Содержит перечисление `TokenType` со всеми типами токенов и класс `Token` для хранения информации о токене.

**Ключевые типы токенов:**
- **Ключевые слова:** `IF`, `ELSE`, `WHILE`, `FOR`, `INT`, `FLOAT`, `BOOL`, `RETURN`, `TRUE`, `FALSE`, `VOID`, `STRUCT`, `FN`
- **Операторы:** `PLUS (+)`, `MINUS (-)`, `STAR (*)`, `SLASH (/)`, `PERCENT (%)`, `ASSIGN (=)`, `EQ_EQ (==)`, `NOT_EQ (!=)`, `LESS (<)`, `GREATER (>)`, `LESS_EQ (<=)`, `GREATER_EQ (>=)`, `AND (&)`, `AND_AND (&&)`, `OR (|)`, `OR_OR (||)`
- **Разделители:** `LPAREN (`, `RPAREN )`, `LBRACE {`, `RBRACE }`, `SEMICOLON ;`, `COMMA ,`
- **Литералы:** `IDENTIFIER`, `INT_LITERAL`, `FLOAT_LITERAL`, `STRING_LITERAL`, `BOOL_LITERAL`
- **Специальные:** `END_OF_FILE`, `INVALID`

#### `errors.py` — иерархия ошибок
``` python
LexicalError              # Базовый класс
├── InvalidCharacterError   # Недопустимый символ
├── UnterminatedStringError # Незакрытая строка
├── UnterminatedCommentError # Незакрытый комментарий
├── InvalidNumberError      # Неправильный формат числа
├── IdentifierTooLongError  # Идентификатор длиннее 255 символов
└── IntegerOutOfRangeError  # Число вне диапазона [-2³¹, 2³¹-1]
```

#### `scanner.py` — основной класс Scanner
Выполняет преобразование исходного кода в токены.

### **Основные методы:**

```
__init__(source) — инициализация с исходным кодом

scan_tokens() — сканирование всех токенов

next_token() — получение следующего токена

peek_token() — просмотр следующего токена без продвижения

is_at_end() — проверка достижения конца файла

get_line() / get_column() — получение текущей позиции
```

### *Внутренние методы для распознавания:*

```
_read_identifier() — чтение идентификаторов и ключевых слов

_read_number() — чтение чисел (int и float)

_read_string() — чтение строк

_read_operator() — чтение операторов

_skip_comment() — пропуск комментариев

cli.py — интерфейс командной строки
```

Обрабатывает аргументы командной строки и запускает сканер.

### 2. Директория tests/ — тестирование

`test_lexer.py` — модульные тесты

#### Проверяет все аспекты работы лексера:

1) Распознавание всех типов токенов

2) Обработка граничных случаев

3) Отслеживание позиции

4) Обработка ошибок

### Тестовые файлы .src

#### Хранят примеры кода для тестирования:

1) `valid/` — корректный код, который должен успешно анализироваться

2) `invalid/` — код с ошибками для проверки обработки ошибок

### 3. Директория docs/ — документация
`language_spec.md`
Спецификация языка в формате EBNF, описывающая:

1) Лексическую грамматику

2) Ключевые слова

3) Правила для идентификаторов

4) Типы литералов

5) Операторы и разделители

6) Обработку пробелов и комментариев
